{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In this notebook we want to show how data analysis can support an internal audit. Therefore, this notebook does not use the data as indicated in the description of the data. Furthermore, the text is in German since I want to link it to a small lecture I'll give to a German audience.\n\n**Comments are welcome!**","metadata":{}},{"cell_type":"markdown","source":"## Ziel\nZiel des Notebooks ist es zu zeigen, wie Datenanalysen eine Prüfung der Revision unterstützen können. Für eine mittelgroße Prüfung (30 - 50 PT) sollte erfahrungsgemäß eine initiale Datenanalyse, wie sie im Folgenden dargestellt ist, nicht mehr als **rund 3 - 5 Tage** in Anspruch nehmen. Diese Herangehensweise ist für eine **große Menge an Fällen** anwendbar und benötigt lediglich\n* einen Zugang zu mit dem Prüfungsinhalt verknüpften Daten, \n* Standardtechniken in einer für Datenanalysen geeigneten Sprache (z.B. R oder Python) und\n* ein grundsätzliches Verständnis für die Daten/gesunden Menschenverstand.\n\nWir führen die Datenanalyse für auf Kaggle verfügbare Incident-Daten durch. Die Methoden kann man analog aber auch für Kreditdaten, Zahlungsverkehrdaten, Personaldaten und viele andere Datenarten anwenden.","metadata":{}},{"cell_type":"markdown","source":"In this notebook we want to show how data analysis can support an internal audit. Therefore, this notebook does not use the data as indicated in the description of the data. Furthermore, the text is in German since I want to link it to a small lecture I'll give to a German audience.\n\n**Comments are welcome!**","metadata":{}},{"cell_type":"markdown","source":"In this notebook we want to show how data analysis can support an internal audit. Therefore, this notebook does not use the data as indicated in the description of the data. Furthermore, the text is in German since I want to link it to a small lecture I'll give to a German audience.\n\n**Comments are welcome!**","metadata":{}},{"cell_type":"markdown","source":"In this notebook we want to show how data analysis can support an internal audit. Therefore, this notebook does not use the data as indicated in the description of the data. Furthermore, the text is in German since I want to link it to a small lecture I'll give to a German audience.\n\n**Comments are welcome!**","metadata":{}},{"cell_type":"markdown","source":"In this notebook we want to show how data analysis can support an internal audit. Therefore, this notebook does not use the data as indicated in the description of the data. Furthermore, the text is in German since I want to link it to a small lecture I'll give to a German audience.\n\n**Comments are welcome!**","metadata":{}},{"cell_type":"markdown","source":"## 0. Vorbemerkung\nZentral für eine gute Prüfung sind:\n* ein klares Prüfungsziel, das sich aus dem Risiko des Prüffelds ableitet,\n* hieraus abgeleitete Prüfungsfragen und\n* ein gutes Verständnis der zugrunde liegenden Prozesse, aus denen die Daten stammen.\n\nAll dies ist für die vorliegenden, auf Kaggle öffentlich verfügbaren Daten **nicht** der Fall. Wir machen daher gewisse **Annahmen**, um dennoch eine stringente Analyse simulieren zu können.\n* Ziel der Prüfung ist die Prüfung der Wirksamkeit und Ordnungsmäßigkeit des Incident-Prozesses\n* Prüfungsfragen sind:\n    * In wie weit ist der Prozess geeignet, Incidents in Abhängigkeit von der Kritikalität zeitgerecht zu schließen?\n    * In wie weit ist die Bearbeitungsqualität zufriedenstellend?\n* Bzgl. Prozess nehmen wir an, es handelt sich um einen typischen Incident-Prozess (gem. Beschreibung der Daten handelt es sich um \"data gathered from the audit system of an instance of the ServiceNowTM platform used by an IT company\")\n\nZiel der Datenanalyse ist es einerseits, übergreifende Auswertungen zu den obigen Fragen zu generieren. Typischerweise hat das Incident-Management sich hier auch selbst Ziele gesetzt, gegen die man prüfen kann - dies kann in dem Beispiel nicht betrachtet werden. Andererseits sollen Ausreißer identifiziert werden. Diese würden dann in der Praxis näher untersucht, um hier potenzielle Schwachstellen im Prozessdesign zu identifizieren. In dem hier aufgeführten Beispiel kann natürlich nur die Definition der risikoorientierten Stichprobe dargestellt werden. ","metadata":{}},{"cell_type":"markdown","source":"## 1. Vorbereitungen:\nLaden der verwendeten Packages und Daten. Wir haben hier das Glück, einen fertigen Datensatz vorzufinden, und nicht verschiedene Datenquellen noch miteinander verbinden zu müssen. Im wirklichen Leben stecken in diesen Schritten oft nicht unerheblicher Aufwand.","metadata":{}},{"cell_type":"code","source":"# Loading packages\nlibrary(tidyverse) # metapackage of all tidyverse packages\nlibrary(plotly) # Für interaktive Grafiken\n","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","execution":{"iopub.status.busy":"2022-08-19T13:04:35.960175Z","iopub.execute_input":"2022-08-19T13:04:35.961463Z","iopub.status.idle":"2022-08-19T13:04:35.973031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading data\nincident_event_log <- read.csv(\"../input/incident-response-log/incident_event_log.csv\")\ndescription <- readLines(\"../input/incident-response-log/Incident_response.txt\")","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:35.992792Z","iopub.execute_input":"2022-08-19T13:04:35.994067Z","iopub.status.idle":"2022-08-19T13:04:37.372039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Die Warnung können wir nach einem Blick in die Datei ignorieren. Neben den eigentlichen Daten liegt eine kurze Beschreibung vor, die wir ausgeben:","metadata":{}},{"cell_type":"code","source":"print(description[-2:-1]) # lines 1 and 2 without information about variables","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:37.373892Z","iopub.execute_input":"2022-08-19T13:04:37.375014Z","iopub.status.idle":"2022-08-19T13:04:37.387112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Als nächstes ein kurzer Blick in die Daten:","metadata":{}},{"cell_type":"code","source":"head(incident_event_log)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:37.388959Z","iopub.execute_input":"2022-08-19T13:04:37.390031Z","iopub.status.idle":"2022-08-19T13:04:37.416118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Offenbar gibt es pro Incident mehrere Zeilen. Die jeweils finalen Einträge scheinen dann in der letzten Zeile zu stehen, wobei auch in den Zeilen davor schon manche Einträge stehen, die man hier vielleicht nicht erwartet hätte (z.B. bei Ticketeröffnung die Spalte \"resolved_by\"). Hier auch nochmal ein Grafik, die die Einträge je Ticketnummer zeigt:","metadata":{}},{"cell_type":"code","source":"incident_event_log$number %>% table() %>% hist(main = \"Anzahl Einträge je Incident\")","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:37.418009Z","iopub.execute_input":"2022-08-19T13:04:37.419158Z","iopub.status.idle":"2022-08-19T13:04:37.526004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wir möchten uns auf die letzte Zeile je Incident konzentrieren. Dies sollte die Zeile sein, in der der Status Closed ist. Wir hätten erwartet, dass die äquivalent dazu ist, dass die Spalte \"active\" den Status \"false\" hat. Dies stimmt grundsätzlich, für eine Zeile allerdings nicht. ","metadata":{}},{"cell_type":"code","source":"incident_event_log %>% filter(incident_state == \"Closed\" & active == \"true\") %>% nrow()\nincident_event_log %>% filter(incident_state != \"Closed\" & active == \"false\")\nincident_event_log %>% filter(number == \"INC0018594\")\n","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:37.527816Z","iopub.execute_input":"2022-08-19T13:04:37.528874Z","iopub.status.idle":"2022-08-19T13:04:37.604663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Beobachtung 1:** Der \"INC0018594\" hat (als einziger Incident) zwischendurch den Status \"incidents_state\" ungleich \"Closed\" und \"active\" gleich false. \n\nIm Folgenden reduzieren wir den Datensatz auf diejenigen Zeilen, in denen der incident_state den Status \"Closed\" hat. ","metadata":{}},{"cell_type":"code","source":"incident_event_log_save <- incident_event_log\nincident_event_log <- incident_event_log %>% filter(incident_state == \"Closed\")","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:37.606523Z","iopub.execute_input":"2022-08-19T13:04:37.607604Z","iopub.status.idle":"2022-08-19T13:04:37.633264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wir überprüfen noch, ob wir tatsächlich für jeden Incident jetzt eine Zeile haben:","metadata":{}},{"cell_type":"code","source":"doppelter_name <- incident_event_log$number[duplicated(incident_event_log$number)]\nprint(paste(\"Anzahl der Incidents, die mehrfach vorkommen: \", length(doppelter_name)))\nprint(paste(\"Anzahl Incidents im Status closed gesamt: \", length(unique(incident_event_log$number))))\n","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:37.635082Z","iopub.execute_input":"2022-08-19T13:04:37.63615Z","iopub.status.idle":"2022-08-19T13:04:37.653079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Angesichts der Größenverhältnisse und der zeitlichen Restriktionen widerstehen wir dem Drang, nach der Ursache der mehrfach vorkommenden Incidents zu suchen. Vielmehr merken wir sie uns für später für eine Stichprobe vor.","metadata":{}},{"cell_type":"markdown","source":"## 2. Univariate Ausreißeranalyse (Bearbeitungsqualität)\nFür die **Bearbeitungsqualität** könnten z.B. folgende Kennzahlen Hinweise geben: \n* reassignment_count: number of times the incident has the group or the support analysts changed;\n* reopen_count: number of times the incident resolution was rejected by the caller\n* Bearbeitungszeit\n\nWir schauen uns die entsprechenden Histogramme einmal an. Zunächst für reassignment_count und reopen_count:","metadata":{}},{"cell_type":"code","source":"incident_event_log %>% ggplot(aes(reassignment_count)) + geom_histogram()\nincident_event_log %>% ggplot(aes(reopen_count)) + geom_histogram()","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:37.655021Z","iopub.execute_input":"2022-08-19T13:04:37.656144Z","iopub.status.idle":"2022-08-19T13:04:38.033578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Die Bearbeitungszeit muss zunächst noch formatiert werden:","metadata":{}},{"cell_type":"code","source":"incident_event_log$h <- as.POSIXct(incident_event_log$resolved_at, format=\"%d/%m/%Y %H:%M\")\nincident_event_log$h2 <- as.POSIXct(incident_event_log$opened_at, format=\"%d/%m/%Y %H:%M\")\nincident_event_log$erledigungszeit <- difftime(incident_event_log$h, incident_event_log$h2, unit = \"days\")\nincident_event_log %>% ggplot(aes(erledigungszeit)) + geom_histogram()","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:38.035429Z","iopub.execute_input":"2022-08-19T13:04:38.036528Z","iopub.status.idle":"2022-08-19T13:04:38.260034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Offensichtlich sind die Grafiken nicht hübsch und es kommt eine Warnung. **Meine dringende Empfehlung ist aber, nicht zeitaufwendig die Grafiken zu verschönern.** Stattdessen kann man die Ergebnisse gut ablesen: Es gibt einzelne Tickets mit hohen Assignment-Scores (> 10) und auch mit reopen_count > 2.\nWir legen eine Stichprobe an, in die wir diese Tickets speichern. Die Grenzen legen wir auf Basis der Grafiken nach Expertenschätzung fest:","metadata":{}},{"cell_type":"code","source":"stichprobe <- incident_event_log %>% filter(reassignment_count > 10)\nprint(paste(\"Anzahl Zeilen: \", nrow(stichprobe)))\nstichprobe$grund <- \"Reassignment hoch\"","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:38.261935Z","iopub.execute_input":"2022-08-19T13:04:38.26302Z","iopub.status.idle":"2022-08-19T13:04:38.282056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h <- incident_event_log %>% filter(reopen_count > 2)\nprint(paste(\"Anzahl Zeilen: \",nrow(h)))\nh$grund <- \"Reopen hoch\"\nstichprobe <- rbind(stichprobe, h)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:38.283878Z","iopub.execute_input":"2022-08-19T13:04:38.284973Z","iopub.status.idle":"2022-08-19T13:04:38.306274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Auch für die Bearbeitungszeit können wir die Grenzen für eine Stichprobe nach Expertenschätzung festlegen. Alternativ kann man auch die 0,1% der Fälle nehmen, die am längsten dauern:","metadata":{}},{"cell_type":"code","source":"hohe_erledigungszeit <- quantile(incident_event_log$erledigungszeit, 0.999, na.rm = T)\nprint(paste(\"Hohe Erledigungszeit:\", hohe_erledigungszeit))\nh <- incident_event_log %>% filter(erledigungszeit > hohe_erledigungszeit)\nprint(paste(\"Anzahl Zeilen: \",nrow(h)))\nh$grund <- \"Erledigungszeit hoch\"\nstichprobe <- rbind(stichprobe, h)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:38.308093Z","iopub.execute_input":"2022-08-19T13:04:38.309188Z","iopub.status.idle":"2022-08-19T13:04:38.336879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Zusätzlich betrachten wir an dieser Stelle noch, ob/warum wir NA-Einträge in den Erledigungszeiten haben:","metadata":{}},{"cell_type":"code","source":"print(paste(\"Anzahl NA-Einträge bei Erledigungszeiten:\",incident_event_log %>% filter(is.na(erledigungszeit)) %>% nrow()))\nprint(\"Einträge in der Spalte resolved_at in diesem Fall:\")\nincident_event_log %>% filter(is.na(erledigungszeit)) %>% select(resolved_at) %>% table()\nprint(\"Einträge in der Spalte resolved_by in diesem Fall:\")\nincident_event_log %>% filter(is.na(erledigungszeit)) %>% select(resolved_by) %>% table()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:38.338752Z","iopub.execute_input":"2022-08-19T13:04:38.339825Z","iopub.status.idle":"2022-08-19T13:04:38.448601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Es ist hier also nur ein \"?\" in der Spalte \"resolved_at\" eingetragen, weshalb natürlich auch keine Erledigungszeit berechnet werden kann. In den meisten Fällen ist allerdings jemand eingetragen, der den Incident erledigt hat.\n\n**Beobachtung 2**: Es gibt fehlende Daten beim Datum, wann ein Incident erledigt wurde.\n\nWir wählen eine Stichprobe, wobei wir auch Fälle betrachten, bei denen die erledigende Person unbekannt ist.","metadata":{}},{"cell_type":"code","source":"h <- incident_event_log %>% filter(is.na(erledigungszeit)) %>% filter(resolved_by == \"?\")\nh <- h[sample(1:nrow(h), 10),] # take sample of 10 elements\nh$grund <- \"resolved_at und resolved_by fehlend\"\nstichprobe <- rbind(stichprobe, h)\n\nh <- incident_event_log %>% filter(is.na(erledigungszeit)) %>% filter(resolved_by != \"?\")\nh <- h[sample(1:nrow(h), 10),] # take sample of 10 elements\nh$grund <- \"resolved_at fehlend\"\nstichprobe <- rbind(stichprobe, h)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:38.450565Z","iopub.execute_input":"2022-08-19T13:04:38.451618Z","iopub.status.idle":"2022-08-19T13:04:38.491634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Zusätzlich wollten wir ja, wie in Kapitel 1 angemerkt, mehrfach vorkommende Incidents in die Stichprobe nehmen: ","metadata":{}},{"cell_type":"code","source":"h <- incident_event_log %>% filter(number %in% doppelter_name)\nh <- h[sample(1:nrow(h), 10),] # take sample of 10 elements\nh$grund <- \"Incident mehrfach\"\nstichprobe <- rbind(stichprobe, h)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:38.493416Z","iopub.execute_input":"2022-08-19T13:04:38.494457Z","iopub.status.idle":"2022-08-19T13:04:38.516111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Kritikalität\nEin Prüfungsfrage lautete gem. Abschnitt 0: *In wie weit ist der Prozess geeignet, Incidents in Abhängigkeit von der Kritikalität zeitgerecht zu schließen?*\n\nEntsprechend ist zunächst auszuwerten, welche Incidents als kritisch angesehen werden können. \n\nAuf eine hohe Kritikalität der Incidents könnten z.B. folgende Variablen hinweisen:\n* impact: description of the impact caused by the incident (values: 1â€“High; 2â€“Medium; 3â€“Low);\n* urgency: description of the urgency informed by the user for the incident resolution (values: 1â€“High; 2â€“Medium; 3â€“Low);\n* priority: calculated by the system based on 'impact' and 'urgency';\n* made_sla: boolean attribute that shows whether the incident exceeded the target SLA;\n\nWobei die letzte Variable ohne weiteres Wissen schwer zu beurteilen ist, ggf. kann hier auch die Erledigungszeit eine Rolle spielen.\n\nInteressant ist auch, für welche Incidents eine Bestätigung der Priorität vorgenommen wurde. \n\nIm Folgenden zeigen wir die Verteilung der Incidents auf diese Variablen durch Histogramme. \n","metadata":{}},{"cell_type":"code","source":"incident_event_log %>% ggplot(aes(impact, fill = u_priority_confirmation)) + geom_histogram(stat=\"count\")\nincident_event_log %>% ggplot(aes(urgency, fill = u_priority_confirmation)) + geom_histogram(stat=\"count\")\nincident_event_log %>% ggplot(aes(priority, fill = u_priority_confirmation))+ geom_histogram(stat=\"count\")\nincident_event_log %>% ggplot(aes(made_sla, fill=priority)) + geom_histogram(stat=\"count\")","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:38.518007Z","iopub.execute_input":"2022-08-19T13:04:38.519071Z","iopub.status.idle":"2022-08-19T13:04:39.594461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Auch hier widerstehen wir der Versuchung, die Grafen z.B. durch schönere Anordnung (grid.arrange, plot_grid) hübscher zu machen. Stattdessen schauen wir uns die Grafen genauer an:\n\n**Beobachtung 3:** Die große Mehrheit wird Medium/Moderate geratet. Es sollte überprüft werden, ob die entsprechenden Einstufungsprozesse angemessen sind.\n\nDie Bestätigung der Priorität findet wie erwartet insb. bei hoch priorisierten Incidents statt. In die Stichprobe nehmen wir ein paar Fälle auf, die hoch priorisiert sind, bei denen es aber dennoch keine Überprüfung gab. ","metadata":{}},{"cell_type":"code","source":"h <- incident_event_log %>% filter(priority == \"1 - Critical\") %>% filter(u_priority_confirmation == \"false\")\nh\nh$grund <- \"Kritische Priorität nicht überprüft\"\nstichprobe <- rbind(stichprobe, h)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:39.596405Z","iopub.execute_input":"2022-08-19T13:04:39.597547Z","iopub.status.idle":"2022-08-19T13:04:39.639679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wie erwartet ist made_sla eher bei kritischen Incidents \"false\". \n\n**Beobachtung 4:** Es gibt niedrig priorisierte Incidents, die dennoch zu einer Nichterfüllung des SLA führen.\n\nWir nehmen hiervon gleich eine Stichprobe:","metadata":{}},{"cell_type":"code","source":"h <- incident_event_log %>% filter(priority == \"4 - Low\") %>% filter(made_sla == \"false\")\nnrow(h)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:39.642294Z","iopub.execute_input":"2022-08-19T13:04:39.643448Z","iopub.status.idle":"2022-08-19T13:04:39.671203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"121 Fälle sind uns zu viel für die Stichprobe, daher ziehen wir hier noch eine Zufallsauswahl.","metadata":{}},{"cell_type":"code","source":"h <- h[sample(1:nrow(h), 20),] # take sample of 20 elements\nh$grund <- \"Niedrig priorisierter Incident bei Nichterfüllung SLA\"\nstichprobe <- rbind(stichprobe, h)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:39.673802Z","iopub.execute_input":"2022-08-19T13:04:39.675085Z","iopub.status.idle":"2022-08-19T13:04:39.689517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Kritikalität und Bearbeitungszeit\n\nDie erste Prüfungsfrage lautete gem. Abschnitt 0: In wie weit ist der Prozess geeignet, Incidents in Abhängigkeit von der Kritikalität zeitgerecht zu schließen?\n\nWenn wir annehmen, dass die Priorität die Kritikalität am besten abbildet, liefert folgender Boxplot eine gute Annäherung an die Frage:","metadata":{}},{"cell_type":"code","source":"incident_event_log %>% ggplot(aes(priority, erledigungszeit)) + geom_boxplot()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:39.691787Z","iopub.execute_input":"2022-08-19T13:04:39.692898Z","iopub.status.idle":"2022-08-19T13:04:39.973904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Beobachtung 5:** Kritischere Incidents werden im Schnitt nicht früher geschlossen, als weniger kritische. Der Prozess ist hier auf die Steuerungswirkung der Priorität zu überprüfen.\n\nWir betrachten das nochmal in Zahlen:","metadata":{}},{"cell_type":"code","source":"incident_event_log %>% group_by(priority) %>% summarise(Durchschnitt = mean(erledigungszeit, na.rm=T), Median = median(erledigungszeit, na.rm=T))","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:39.975723Z","iopub.execute_input":"2022-08-19T13:04:39.976828Z","iopub.status.idle":"2022-08-19T13:04:40.002982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Auch hier nehmen wir die kritischen mit der höchsten Bearbeitungszeit in die Stichprobe.","metadata":{}},{"cell_type":"code","source":"h <- incident_event_log %>% filter(priority == \"1 - Critical\") %>% filter(erledigungszeit > 100)\nh$grund <- \"Kritischer Incident mit hoher Erledigungszeit\"\nstichprobe <- rbind(stichprobe, h)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:40.004783Z","iopub.execute_input":"2022-08-19T13:04:40.005867Z","iopub.status.idle":"2022-08-19T13:04:40.032173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Wechsel der Priorität im Verlauf\nIn den vorhergehenden Auswertungen haben wir implizit angenommen, dass die Priorität über den Incident unverändert war. Es ist aber durchaus möglich, dass z.B. aufgrund von langen Bearbeitungszeiten ein Incident seine Kritikalität ändert. Wir untersuchen das im Folgenden für kritische Incidents.","metadata":{}},{"cell_type":"code","source":"# Alle kritischen Incidents:\nkritische_incidents <- incident_event_log %>% filter(priority == \"1 - Critical\")\n\n# Alle am Ende kritischen Incidents mit allen Zeilen davor\nkritische_incidents_alle_eintraege <- incident_event_log_save %>% filter(number %in% kritische_incidents$number)\n\n# Incidents, die am Ende kritisch waren, zwischendurch aber nicht\nkritische_incidents_zwischendurch_andere_priority <- kritische_incidents_alle_eintraege %>% filter(priority != \"1 - Critical\")\nprint(paste(\"Anzahl Incidents, die am Ende kritisch waren, zwischendurch aber nicht: \", length(unique(kritische_incidents_zwischendurch_andere_priority$number))))\n\n# Incident numbers, die immer kritisch waren\nimmer_kritisch <- setdiff(kritische_incidents$number, kritische_incidents_zwischendurch_andere_priority$number)\n\n# Incidents (alle Spalten), die immer kritisch waren\nimmer_kritische_incidents <- incident_event_log %>% filter(number %in% immer_kritisch)\n\n# Mean und Median dieser Incidents\nprint(paste(\"Durchschnittliche Erledigungszeit der Incidents, die immer kritisch waren: \", mean(immer_kritische_incidents$erledigungszeit)))\nprint(paste(\"Median der Erledigungszeit der Incidents, die immer kritisch waren: \", median(immer_kritische_incidents$erledigungszeit)))","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:40.034063Z","iopub.execute_input":"2022-08-19T13:04:40.035124Z","iopub.status.idle":"2022-08-19T13:04:40.092465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Man sieht, dass die Ergebnisse besser sind, wenn die Incidents von Anfang an kritisch waren. Dennoch ist die Durchschnittszeit noch höher als bei High und nicht niedriger als bei Moderate und der Median höher als bei Moderate und Low.","metadata":{}},{"cell_type":"markdown","source":"## 6. Multivariate Analyse\nWir haben oben bereits einzelne Analysen gemacht, die mehrere Variablen beinhalteten (z.B. Erledigungszeit in Abhängigkeit von der Kritikalität). In diesem Kapitel möchten wir aber zeigen, wie man mit einer relativ großen Menge an Variablen umgehen kann. \n\nZunächst einmal müssen wir alle relevanten Variablen in numerische Variablen umwandeln. Der Einfachheit halber wandeln wir dabei auch ordinale Variablen, als seien sie metrisch (d.h. z.B. der Abstand zwischen \"Critical\" und \"High\" ist der gleiche wie zwischen \"High\" und \"Moderate\").\n\nZusätzlich entfernen wir die Incidents, deren Erledigungszeit NA ist.\n\nOutput ist eine Zusammenfassung der verschiedenen Variablen.","metadata":{}},{"cell_type":"code","source":"df <- incident_event_log\ndf <- df %>% select(priority, reassignment_count, reopen_count, erledigungszeit, made_sla, u_priority_confirmation)\ndf$priority[df$priority == \"1 - Critical\"] <- 3\ndf$priority[df$priority == \"2 - High\"] <- 2\ndf$priority[df$priority == \"3 - Moderate\"] <- 1\ndf$priority[df$priority == \"4 - Low\"] <- 0\ndf$priority <- as.numeric(df$priority)\n\ndf$made_sla[df$made_sla == \"false\"] <- 0\ndf$made_sla[df$made_sla == \"true\"] <- 1\ndf$made_sla <- as.numeric(df$made_sla)\n\ndf$u_priority_confirmation[df$u_priority_confirmation == \"false\"] <- 0\ndf$u_priority_confirmation[df$u_priority_confirmation == \"true\"] <- 1\ndf$u_priority_confirmation <- as.numeric(df$u_priority_confirmation)\n\ndf$erledigungszeit <- as.numeric(df$erledigungszeit)\n\ndf <- df %>% filter(!is.na(erledigungszeit))\n\nsummary(df)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:40.094318Z","iopub.execute_input":"2022-08-19T13:04:40.095373Z","iopub.status.idle":"2022-08-19T13:04:40.158716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6.1 Principal Component-Analyse\nWir führen nun eine Principal Component-Analyse durch. Dies ist eine der gängigsten Methoden, um hochdimensionale Daten mit möglichst wenig Informationsverlust zweidimensional anzuzeigen. Die Methode hat natürlich auch Nachteile/Einschränkungen (insb., dass lediglich lineare Transformationen möglich sind und die optimale Wahl der Achsen bzw. der Informationsverlust nur unter strikten Bedingungen bewiesen werden kann), worauf wir hier aber nicht eingehen. Allerdings macht es durchaus Sinn zu prüfen, wie viel \"Prozent der Information\" man mit zwei Achsen sehen kann.","metadata":{}},{"cell_type":"code","source":"df.pca <- prcomp(df, center = TRUE, scale. = TRUE)\nsummary(df.pca)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:40.160625Z","iopub.execute_input":"2022-08-19T13:04:40.161749Z","iopub.status.idle":"2022-08-19T13:04:40.184425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Mit zwei Achsen kann man also rund 47% der Informationen sehen, was bei 6 Dimensionen kein besonders hoher Wert ist (bei zufälligen Achsen wären es im Schnitt 33%).\n\nWir plotten nun die beiden ersten Achsen.","metadata":{}},{"cell_type":"code","source":"# Wandle df.pca in data.frame um\ndf.pca_data_frame <- df.pca[[\"x\"]] %>% data.frame()\n\n# Speichere incident-Namen\nnamen <- incident_event_log %>% filter(!is.na(erledigungszeit))\nnamen <- namen$number\n\n#plot\nplot_ly(df.pca_data_frame, x=~PC1, y=~PC2, text=namen, type=\"scatter\")","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:40.187066Z","iopub.execute_input":"2022-08-19T13:04:40.188647Z","iopub.status.idle":"2022-08-19T13:04:41.664846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Die einzelnen Punkte am Rand betrachten wir als Ausreißer. Als pragmatischen Ansatz fahren wir mit der Maus über diese Punkte und schreiben sie in einen Vektor. Wir zeichnen die Grafik zur Kontrolle bzw. zur besseren Nachvollziehbarkeit nochmal (diesmal ohne interaktives Element) und markieren dabei die Elemente des Vektors farblich.","metadata":{}},{"cell_type":"code","source":"ausreisser <- c(\"INC0012499\", \"INC0007521\", \"INC0005927\", \"INC0015902\", \"INC0002129\",\"INC0007521\", \"INC0002780\" , \"INC0011665\", \"INC0001929\", \"INC0007593\",\"INC0002483\",\"INC0003419\", \"INC0007229\", \"INC0019396\", \"INC0011206\", \"INC0019595\", \"INC0003982\", \"INC0004210\", \"INC0020718\", \"INC0007349\", \"INC0012815\", \"INC0019131\")\ndf.pca_data_frame$namen <- namen\ndf.pca_data_frame$ausreisser <- ifelse(namen %in% ausreisser, 1, 0)\ndf.pca_data_frame %>% ggplot(aes(PC1, PC2, colour=as.factor(ausreisser))) + geom_point()","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:41.666731Z","iopub.execute_input":"2022-08-19T13:04:41.667875Z","iopub.status.idle":"2022-08-19T13:04:42.711657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Die wesentliche Frage ist: Haben wir durch diese Analyse neue Ausreißer entdeckt, die wir in der univariaten Analse noch nicht entdeckt hatten. ","metadata":{}},{"cell_type":"code","source":"print(paste(\"Anzahl multivariater Ausreißer: \", length(unique(ausreisser))))\nh <- setdiff(ausreisser, stichprobe$number)\nprint(paste(\"Anzahl multivariater Ausreißer, die nicht in der univariaten Ausreißeranalyse identifiziert wurden: \", length(h)))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:42.713629Z","iopub.execute_input":"2022-08-19T13:04:42.714669Z","iopub.status.idle":"2022-08-19T13:04:42.729812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"4 von 21 Ausreißer sind also \"neu\". Die multivariate Analyse liefert also neue Informationen, allerdings nicht besonders viele.","metadata":{}},{"cell_type":"code","source":"h <- incident_event_log %>% filter(number %in% ausreisser)\nh$grund <- \"Ausreißer gem. PCA\"\nstichprobe <- rbind(stichprobe, h)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:42.731605Z","iopub.execute_input":"2022-08-19T13:04:42.732739Z","iopub.status.idle":"2022-08-19T13:04:42.752946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Natürlich ist eine solche, rein graphische Analyse angreifbar (wobei es nur um eine Stichprobenermittlung geht). Es gibt natürlich auch Algorithmen, die ähnliche Analysen vornehmen, zum Beispiel auf Basis von k-nearest neighbourhoods.","metadata":{}},{"cell_type":"markdown","source":"### 6.2 Autoencoder\nWir haben oben ein paar Schwächen der Principal Component Analyse angesprochen. Deshalb verwenden wir hier noch ein zweites, nichtlineares Verfahren zur Ausreißeranalyse. Wir trainieren ein kleines neuronales Netz, das die Daten möglichst gut kompimieren soll. Diejenigen Datensätze, bei denen die Komprimierung weit entfernt vom Original ist, sind Ausreißer.\n\nZunächst bereiten wir die Daten und Pakete vor. ","metadata":{}},{"cell_type":"code","source":"# Bibliothek laden\nlibrary(autoencoder)\nlibrary(scales)\n\n# Variablen skalieren\ndf_scaled <- sapply(df, rescale)\nsummary(df_scaled)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:42.754863Z","iopub.execute_input":"2022-08-19T13:04:42.75599Z","iopub.status.idle":"2022-08-19T13:04:42.783476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Jetzt werfen wir das Modell an. Gemäß Package ist das Modell insbesondere für \"sparse Autoencoders\" (um bei vielen Variablen Overfitting zu vermeiden). Das ist hier nicht notwendig, weshalb wir den Parameter beta (weight of sparsity penalty term) auf 0 setzen. Selbstverständlich kann man hier auch andere Packages verwenden. ","metadata":{}},{"cell_type":"code","source":"# Berechne Modell\nset.seed(123)\nmodel <- autoencode(df_scaled, beta = 0, rho = 0.01, epsilon = 0.001, N.hidden = 3, lambda = 0.0002, rescale.flag = FALSE)\n# Berechne Vorhersage des Modells\nergebnis <- predict(model, df_scaled, hidden.output = FALSE)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:04:42.786104Z","iopub.execute_input":"2022-08-19T13:04:42.787333Z","iopub.status.idle":"2022-08-19T13:05:03.869992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wir berechnen nun die Abweichungen zwischen Modell-Vorhersage und Ist-Werten und zeichnen diese in ein Histogramm. Dabei markieren wir diejenigen Incidents, die bereits in der Stichprobe sind:","metadata":{}},{"cell_type":"code","source":"# Berechne die Abweichung zwischen der Vorhersage und den Ist-Werten (je Variable und je Incident)\nabweichung <- as.matrix(df_scaled) - ergebnis$X.output\n# Berechne das Quadrat hiervon\nabweichung_2 <- abweichung^2\n# Berechne die Summe über alle quadratischen Abweichungen je Incident\nabweichung_gesamt <- rowSums(abweichung_2)\n# Nehme diese mit den Namen in ein Dataframe\nabweichung_df <- data.frame(abweichung_gesamt, namen)\ncolnames(abweichung_df) <- c(\"Abweichung\", \"IncidentName\")\nabweichung_df$Ist_in_Stichprobe <- ifelse(abweichung_df$IncidentName %in% stichprobe$number, \"ja\", \"nein\")\n\n# Zeichne Histogramm\ng <- abweichung_df %>% ggplot(aes(Abweichung, fill = Ist_in_Stichprobe)) + geom_histogram()\nggplotly(g)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:05:03.872494Z","iopub.execute_input":"2022-08-19T13:05:03.873958Z","iopub.status.idle":"2022-08-19T13:05:05.187513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Es sind im Vergleich zu allen Incidents nur sehr wenige in der Stichprobe, weshalb man sie im Diagramm nicht erkennt. Wählt man aber einen Bereich von ca. Count 0 - 50, Abweichung 0,5 - 1,1 aus, erkennt man gut, dass Incidents mit der höchsten Abweichung schon in der Stichprobe enthalten sind. Ab ca. einer Abweichung von 0,5 sind aber auch Incidents vorhanden, die noch nicht in der Stichprobe sind. Wir setzen die Grenze zur Einbindung daher auf 0,4.","metadata":{}},{"cell_type":"code","source":"hh <- abweichung_df %>% filter(Abweichung > 0.4)\nprint(paste(\"Anzahl Incidents mit Abweichung > 0,4: \",length(unique(hh$IncidentName))))\nstichprobe_in_abweichung <- stichprobe %>% filter(number %in% hh$IncidentName)\nprint(paste(\"Davon bereits in der Stichprobe enthalten: \", length(unique(stichprobe_in_abweichung$number))))","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:05:05.189389Z","iopub.execute_input":"2022-08-19T13:05:05.190463Z","iopub.status.idle":"2022-08-19T13:05:05.220999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wir fügen die Punkte der Stichprobe hinzu:","metadata":{}},{"cell_type":"code","source":"h <- incident_event_log %>% filter(number %in% hh$IncidentName)\nh$grund <- \"Ausreißer gem. Autoencoder\"\nstichprobe <- rbind(stichprobe, h)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:05:05.222954Z","iopub.execute_input":"2022-08-19T13:05:05.22414Z","iopub.status.idle":"2022-08-19T13:05:05.247098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Abschluss\nWir haben in der kurzen Analyse wichtige Informationen für unsere Prüfung erhalten:\n* Ein grundsätzliches Verständnis für das Mengengerüst des Prozesses\n* Mehrere **Beobachtungen**, die Hinweise auf Prozessschwächen sein können\n* Eine **risikoorientierte Stichrpobe**, die Ausgangspunkt für weitere Untersuchungen sein kann\n\nDa für die Analyse nur ungefähr 10% der veranschlagten Zeit verwendet wurden, ist auch noch genug Zeit, diesen Punkten nachzugehen. Selbstverständlich könnte man noch viel mehr Analysen auf diesen Daten machen, aber wird es erfahrungsgemäß schwer, allen Auffälligkeiten tatsächlich in der gebotenen Genauigkeit nachzugehen.\n\nWir schließen mit einem kurzen Blick auf die Verteilung der Stichprobe nach verschiedenen Gründen. Es macht Sinn, die Tickets zuerst zu betrachten, die aus mehrfachen Grund in der Stichprobe sind:","metadata":{}},{"cell_type":"code","source":"stichprobe$grund %>% table()\nHaeufigkeit_Incident_in_Stichprobe <- stichprobe %>% group_by(number) %>% summarise(count = n())\nhist(Haeufigkeit_Incident_in_Stichprobe$count)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T13:05:05.249338Z","iopub.execute_input":"2022-08-19T13:05:05.250736Z","iopub.status.idle":"2022-08-19T13:05:05.330177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Und jetzt geht die Detailarbeit los...","metadata":{}}]}